version: '3.9'

volumes:
  s3-data: {}
  prometheus-data: {}
  grafana-data: {}

services:
  test-mlflow-db:
    image: postgres:14.3
    container_name: test-mlflow-db
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_SERVER_HOST: ${POSTGRES_SERVER_HOST}
      POSTGRES_SERVER_PORT: ${POSTGRES_SERVER_PORT}
    expose:
      - "5432"

  test-minio:
    image: minio/minio:RELEASE.2022-05-19T18-20-59Z
    container_name: test-minio
    command: server /data --console-address ":9001"
    expose:
      - "9000"
      - "9001"
    ports:
      - "127.0.0.1:9000:9000"
      - "127.0.0.1:9001:9001"
    volumes:
      - "s3-data:/data"
    environment:
      MINIO_SITE_REGION: ${AWS_DEFAULT_REGION}
      MINIO_ROOT_USER: ${AWS_ACCESS_KEY_ID}
      MINIO_ROOT_PASSWORD: ${AWS_SECRET_ACCESS_KEY}

  createbuckets:
    image: minio/mc
    container_name: test-createbuckets
    depends_on:
      - test-minio
    entrypoint: >
      /bin/sh -c "
      echo sleep 15;
      sleep 15;
      /usr/bin/mc config host add myminio http://minio:9000 ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY};
      /usr/bin/mc mb myminio/${EXPERIMENT_NAME};
      exit 0;
      "

  mlflow-server:
    build:
      context: ../../app
      dockerfile: Dockerfile
    image: ${DOCKERHUB_USERNAME}/${DOCKERHUB_REPOSITORY}:${IMAGE_TAG}
    container_name: test-mlflow-server
    environment:
      AWS_REGION: ${AWS_REGION}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    expose:
      - "5000"
    ports:
      - "127.0.0.1:5000:5000"
    command: mlflow server --host 0.0.0.0 --backend-store-uri postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_SERVER_HOST}:${POSTGRES_SERVER_PORT}/${POSTGRES_DB} --default-artifact-root s3://${EXPERIMENT_NAME}/test-mlflow
    depends_on:
      - test-minio

  prediction-service:
    build:
      context: ../../app
      dockerfile: Dockerfile
    image: ${DOCKERHUB_USERNAME}/${DOCKERHUB_REPOSITORY}:${IMAGE_TAG}
    container_name: test-prediction-service
    environment:
      AWS_REGION: ${AWS_REGION}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MLFLOW_ENABLED: "True"
      TRACKING_SERVER_HOST: ${TRACKING_SERVER_HOST}
      TRACKING_SERVER_PORT: ${TRACKING_SERVER_PORT}
      EXPERIMENT_NAME: ${EXPERIMENT_NAME}
      DEFAULT_MODEL_ENABLED: ${DEFAULT_MODEL_ENABLED}
      DEFAULT_PREPROCESSOR_ENABLED: ${DEFAULT_PREPROCESSOR_ENABLED}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      MONITORING_ENABLED: "False"
      EVIDENTLY_SERVICE_HOST: ${EVIDENTLY_SERVICE_HOST}
      EVIDENTLY_SERVICE_PORT: ${EVIDENTLY_SERVICE_PORT}
      MONGODB_CLUSTER_URL: ${MONGODB_CLUSTER_URL}
      MONGODB_USERNAME: ${MONGODB_USERNAME}
      MONGODB_PASSWORD: ${MONGODB_PASSWORD}
      PREDICTION_DATABASE_NAME: ${PREDICTION_DATABASE_NAME}
    command: "gunicorn --bind=0.0.0.0:8081 predict:app"
    volumes:
      - ./app/model:/app/model
      - ./app/preprocessor:/app/preprocessor
    expose:
      - "8081"
    ports:
      - "8081:8081"
    depends_on:
      - mlflow-server
    restart: on-failure

  prefect:
    build:
      context: ../../app
      dockerfile: Dockerfile
    image: ${DOCKERHUB_USERNAME}/${DOCKERHUB_REPOSITORY}:${IMAGE_TAG}
    container_name: test-prefect
    environment:
      KAGGLE_USERNAME: ${KAGGLE_USERNAME}
      KAGGLE_KEY: ${KAGGLE_KEY}
      EXPERIMENT_NAME: ${EXPERIMENT_NAME}
      AWS_REGION: ${AWS_REGION}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      TRACKING_SERVER_HOST: ${TRACKING_SERVER_HOST}
      TRACKING_SERVER_PORT: ${TRACKING_SERVER_HOST}
      MODEL_REGISTRY_NAME: ${MODEL_REGISTRY_NAME}
      MODEL_SEARCH_ITERATIONS: ${MODEL_SEARCH_ITERATIONS}
    command: "prefect orion start --host=0.0.0.0"
    volumes:
      - ./data:/app/data
      - ./app/model:/app/model
      - ./app/preprocessor:/app/preprocessor
    expose:
      - "4200"
    ports:
      - "127.0.0.1:4200:4200"
    depends_on:
      - mlflow-server
    restart: on-failure
